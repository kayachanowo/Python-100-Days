{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 泰坦尼克号生存率预测\n",
    "<font size=3>\n",
    "1.项目基本信息\n",
    "\n",
    "项目的背景是大家都熟知的发生在1912年的泰坦尼克号沉船灾难，这次灾难导致2224名船员和乘客中有1502人遇难。而哪些人幸存那些人丧生并非完全随机。比如说你碰巧搭乘了这艘游轮，而你碰巧又是一名人见人爱，花见花开的一等舱小公主，那活下来的概率就很大了，但是如果不巧你只是一名三等舱的抠脚大汉，那只有自求多福了。也就是说在这生死攸关的情况下，生存与否与性别，年龄，阶层等因素是有关系的，如果把这些因素作为特征，生存的结果作为预测目标，就可以建立一个典型的二分类机器学习模型。在这个项目中提供了部分的乘客名单，包括各种维度的特征以及是否幸存的标签，存在train.csv文件中，这是我们训练需要的数据；另一个test.csv文件是我们需要预测的乘客名单，只有相应的特征。我们要做的工作就是通过对训练数据的特征与生存关系进行探索，构建合适的机器学习的模型，再用这个模型预测测试文件中乘客的幸存情况，并将结果保存提交给kaggle。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "目录\n",
    "    \n",
    "1. 提出问题（Business Understanding ）\n",
    "    \n",
    "2. 理解数据（Data Understanding）\n",
    "    \n",
    " * 采集数据\n",
    " * 导入数据\n",
    " * 查看数据集信息\n",
    "3. 数据清洗（Data Preparation ）\n",
    "    \n",
    " * 数据预处理\n",
    " * 特征工程（Feature Engineering）\n",
    "    \n",
    "4. 构建模型（Modeling） \n",
    "    \n",
    "5. 模型评估（Evaluation） \n",
    "    \n",
    "6. 方案实施 （Deployment）\n",
    "    \n",
    " * 提交结果到Kaggle\n",
    " * 报告撰写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.提出问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么样的人在泰坦尼克号中更容易存活？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.理解数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 采集数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从Kaggle泰坦尼克号项目页面下载数据：https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略警告提示\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#导入处理数据包\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据\n",
    "#训练数据集\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "#测试数据集\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "#这里要记住训练数据集有891条数据，方便后面从中拆分出测试数据集用于提交Kaggle结果\n",
    "print ('训练数据集:',train.shape,'测试数据集:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowNum_train=train.shape[0]\n",
    "rowNum_test=test.shape[0]\n",
    "print('kaggle训练数据集有多少行数据：',rowNum_train,\n",
    "     ',kaggle测试数据集有多少行数据：',rowNum_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并数据集，方便同时对两个数据集进行清洗\n",
    "full = train.append( test , ignore_index = True )\n",
    "\n",
    "print ('合并后的数据集:',full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 查看数据集信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看数据\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "describe只能查看数据类型的描述统计信息，对于其他类型的数据不显示，比如字符串类型姓名（name），客舱号（Cabin）\n",
    "这很好理解，因为描述统计指标是计算数值，所以需要该列的数据类型是数据\n",
    "'''\n",
    "#获取数据类型列的描述统计信息\n",
    "full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每一列的数据类型，和数据总数\n",
    "full.info()\n",
    "'''\n",
    "我们发现数据总共有1309行。\n",
    "其中数据类型列：年龄（Age）、船舱号（Cabin）里面有缺失数据：\n",
    "1）年龄（Age）里面数据总数是1046条，缺失了1309-1046=263，缺失率263/1309=20%\n",
    "2）船票价格（Fare）里面数据总数是1308条，缺失了1条数据\n",
    "\n",
    "字符串列：\n",
    "1）登船港口（Embarked）里面数据总数是1307，只缺失了2条数据，缺失比较少\n",
    "2）船舱号（Cabin）里面数据总数是295，缺失了1309-295=1014，缺失率=1014/1309=77.5%，缺失比较大\n",
    "这为我们下一步数据清洗指明了方向，只有知道哪些数据缺失数据，我们才能有针对性的处理。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.数据清洗（Data Preparation ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  缺失值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前面，理解数据阶段，我们发现数据总共有1309行。\n",
    "其中数据类型列：年龄（Age）、船舱号（Cabin）里面有缺失数据。\n",
    "字符串列：登船港口（Embarked）、船舱号（Cabin）里面有缺失数据。\n",
    "\n",
    "这为我们下一步数据清洗指明了方向，只有知道哪些数据缺失数据，我们才能有针对性的处理。\n",
    "\n",
    "很多机器学习算法为了训练模型，要求所传入的特征中不能有空值。\n",
    "\n",
    "\n",
    "1. 如果是数值类型，用平均值取代\n",
    "2. 如果是分类数据，用最常见的类别取代\n",
    "3. 使用模型预测缺失值，例如：K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "我们发现数据总共有1309行。\n",
    "其中数据类型列：年龄（Age）、船舱号（Cabin）里面有缺失数据：\n",
    "1）年龄（Age）里面数据总数是1046条，缺失了1309-1046=263，缺失率263/1309=20%\n",
    "2）船票价格（Fare）里面数据总数是1308条，缺失了1条数据\n",
    "\n",
    "对于数据类型，处理缺失值最简单的方法就是用平均数来填充缺失值\n",
    "'''\n",
    "print('处理前：')\n",
    "full.info()\n",
    "#年龄(Age)\n",
    "full['Age']=full['Age'].fillna( full['Age'].mean() )\n",
    "#船票价格(Fare)\n",
    "full['Fare'] = full['Fare'].fillna( full['Fare'].mean() )\n",
    "print('处理后：')\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查数据处理是否正常\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "总数据是1309\n",
    "字符串列：\n",
    "1）登船港口（Embarked）里面数据总数是1307，只缺失了2条数据，缺失比较少\n",
    "2）船舱号（Cabin）里面数据总数是295，缺失了1309-295=1014，缺失率=1014/1309=77.5%，缺失比较大\n",
    "'''\n",
    "#登船港口（Embarked）：查看里面数据长啥样\n",
    "'''\n",
    "出发地点：S=英国南安普顿Southampton\n",
    "途径地点1：C=法国 瑟堡市Cherbourg\n",
    "途径地点2：Q=爱尔兰 昆士敦Queenstown\n",
    "'''\n",
    "full['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "分类变量Embarked，看下最常见的类别，用其填充\n",
    "'''\n",
    "full['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "从结果来看，S类别最常见。我们将缺失值填充为最频繁出现的值：\n",
    "S=英国南安普顿Southampton\n",
    "'''\n",
    "full['Embarked'] = full['Embarked'].fillna( 'S' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#船舱号（Cabin）：查看里面数据长啥样\n",
    "full['Cabin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#缺失数据比较多，船舱号（Cabin）缺失值填充为U，表示未知（Uknow） \n",
    "full['Cabin'] = full['Cabin'].fillna( 'U' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查数据处理是否正常\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看最终缺失值处理情况，记住生成情况（Survived）这里一列是我们的标签，用来做机器学习预测的，不需要处理这一列\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1数据分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据类型，分为3种数据类型。并对类别数据处理：用数值代替类别，并进行One-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1.数值类型：\n",
    "乘客编号（PassengerId），年龄（Age），船票价格（Fare），同代直系亲属人数（SibSp），不同代直系亲属人数（Parch）\n",
    "2.时间序列：无\n",
    "3.分类数据：\n",
    "1）有直接类别的\n",
    "乘客性别（Sex）：男性male，女性female\n",
    "登船港口（Embarked）：出发地点S=英国南安普顿Southampton，途径地点1：C=法国 瑟堡市Cherbourg，出发地点2：Q=爱尔兰 昆士敦Queenstown\n",
    "客舱等级（Pclass）：1=1等舱，2=2等舱，3=3等舱\n",
    "2）字符串类型：可能从这里面提取出特征来，也归到分类数据中\n",
    "乘客姓名（Name）\n",
    "客舱号（Cabin）\n",
    "船票编号（Ticket）\n",
    "'''\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 分类数据：有直接类别的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 乘客性别（Sex）：\n",
    "男性male，女性female\n",
    "2. 登船港口（Embarked）：出发地点S=英国南安普顿Southampton，途径地点1：C=法国 瑟堡市Cherbourg，出发地点2：Q=爱尔兰 昆士敦Queenstown\n",
    "3. 客舱等级（Pclass）：1=1等舱，2=2等舱，3=3等舱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  性别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看性别数据这一列\n",
    "full['Sex'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "将性别的值映射为数值\n",
    "男（male）对应数值1，女（female）对应数值0\n",
    "'''\n",
    "sex_mapDict={'male':1,\n",
    "            'female':0}\n",
    "#map函数：对Series每个数据应用自定义的函数计算\n",
    "full['Sex']=full['Sex'].map(sex_mapDict)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 登船港口(Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "登船港口(Embarked)的值是：\n",
    "出发地点：S=英国南安普顿Southampton\n",
    "途径地点1：C=法国 瑟堡市Cherbourg\n",
    "途径地点2：Q=爱尔兰 昆士敦Queenstown\n",
    "'''\n",
    "#查看该类数据内容\n",
    "full['Embarked'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放提取后的特征\n",
    "embarkedDf = pd.DataFrame()\n",
    "\n",
    "'''\n",
    "使用get_dummies进行one-hot编码，产生虚拟变量（dummy variables），列名前缀是Embarked\n",
    "'''\n",
    "embarkedDf = pd.get_dummies( full['Embarked'] , prefix='Embarked' )\n",
    "embarkedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加one-hot编码产生的虚拟变量（dummy variables）到泰坦尼克号数据集full\n",
    "full = pd.concat([full,embarkedDf],axis=1)\n",
    "\n",
    "'''\n",
    "因为已经使用登船港口(Embarked)进行了one-hot编码产生了它的虚拟变量（dummy variables）\n",
    "所以这里把登船港口(Embarked)删掉\n",
    "'''\n",
    "full.drop('Embarked',axis=1,inplace=True)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "上面drop删除某一列代码解释：\n",
    "因为drop(name,axis=1)里面指定了name是哪一列，比如指定的是A这一列，axis=1表示按行操作。\n",
    "那么结合起来就是把A列里面每一行删除，最终结果是删除了A这一列.\n",
    "简单来说，使用drop删除某几列的方法记住这个语法就可以了：drop([列名1,列名2],axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 客舱等级（Pclass）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "客舱等级(Pclass):\n",
    "1=1等舱，2=2等舱，3=3等舱\n",
    "'''\n",
    "#存放提取后的特征\n",
    "pclassDf = pd.DataFrame()\n",
    "\n",
    "#使用get_dummies进行one-hot编码，列名前缀是Pclass\n",
    "pclassDf = pd.get_dummies( full['Pclass'] , prefix='Pclass' )\n",
    "pclassDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加one-hot编码产生的虚拟变量（dummy variables）到泰坦尼克号数据集full\n",
    "full = pd.concat([full,pclassDf],axis=1)\n",
    "\n",
    "#删掉客舱等级（Pclass）这一列\n",
    "full.drop('Pclass',axis=1,inplace=True)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 分类数据：字符串类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字符串类型：可能从这里面提取出特征来，也归到分类数据中，这里数据有：\n",
    "\n",
    "1. 乘客姓名（Name）\n",
    "2. 客舱号（Cabin）\n",
    "3. 船票编号（Ticket）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从姓名中提取头衔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "查看姓名这一列长啥样\n",
    "注意到在乘客名字（Name）中，有一个非常显著的特点：\n",
    "乘客头衔每个名字当中都包含了具体的称谓或者说是头衔，将这部分信息提取出来后可以作为非常有用一个新变量，可以帮助我们进行预测。\n",
    "例如：\n",
    "Braund, Mr. Owen Harris\n",
    "Heikkinen, Miss. Laina\n",
    "Oliva y Ocana, Dona. Fermina\n",
    "Peter, Master. Michael J\n",
    "'''\n",
    "full[ 'Name' ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习从字符串中提取头衔，例如Mr\n",
    "#split用于字符串分割，返回一个列表\n",
    "#我们看到姓名中'Braund, Mr. Owen Harris'，逗号前面的是“名”，逗号后面是‘头衔. 姓’\n",
    "name1='Braund, Mr. Owen Harris'\n",
    "'''\n",
    "split用于字符串按分隔符分割，返回一个列表。这里按逗号分隔字符串\n",
    "也就是字符串'Braund, Mr. Owen Harris'被按分隔符,'拆分成两部分[Braund,Mr. Owen Harris]\n",
    "你可以把返回的列表打印出来瞧瞧，这里获取到列表中元素序号为1的元素，也就是获取到头衔所在的那部分，即Mr. Owen Harris这部分\n",
    "'''\n",
    "#Mr. Owen Harris\n",
    "str1=name1.split( ',' )[1] \n",
    "'''\n",
    "继续对字符串Mr. Owen Harris按分隔符'.'拆分，得到这样一个列表[Mr, Owen Harris]\n",
    "这里获取到列表中元素序号为0的元素，也就是获取到头衔所在的那部分Mr\n",
    "'''\n",
    "#Mr.\n",
    "str2=str1.split( '.' )[0]\n",
    "#strip() 方法用于移除字符串头尾指定的字符（默认为空格）\n",
    "str3=str2.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "定义函数：从姓名中获取头衔\n",
    "'''\n",
    "def getTitle(name):\n",
    "    str1=name.split( ',' )[1] #Mr. Owen Harris\n",
    "    str2=str1.split( '.' )[0]#Mr\n",
    "    #strip() 方法用于移除字符串头尾指定的字符（默认为空格）\n",
    "    str3=str2.strip()\n",
    "    return str3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放提取后的特征\n",
    "titleDf = pd.DataFrame()\n",
    "#map函数：对Series每个数据应用自定义的函数计算\n",
    "titleDf['Title'] = full['Name'].map(getTitle)\n",
    "titleDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "定义以下几种头衔类别：\n",
    "Officer政府官员\n",
    "Royalty王室（皇室）\n",
    "Mr已婚男士\n",
    "Mrs已婚妇女\n",
    "Miss年轻未婚女子\n",
    "Master有技能的人/教师\n",
    "'''\n",
    "#姓名中头衔字符串与定义头衔类别的映射关系\n",
    "title_mapDict = {\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "                    }\n",
    "\n",
    "#map函数：对Series每个数据应用自定义的函数计算\n",
    "titleDf['Title'] = titleDf['Title'].map(title_mapDict)\n",
    "\n",
    "#使用get_dummies进行one-hot编码\n",
    "titleDf = pd.get_dummies(titleDf['Title'])\n",
    "titleDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加one-hot编码产生的虚拟变量（dummy variables）到泰坦尼克号数据集full\n",
    "full = pd.concat([full,titleDf],axis=1)\n",
    "\n",
    "#删掉姓名这一列\n",
    "full.drop('Name',axis=1,inplace=True)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从客舱号中提取客舱类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#补充知识：匿名函数\n",
    "'''\n",
    "python 使用 lambda 来创建匿名函数。\n",
    "所谓匿名，意即不再使用 def 语句这样标准的形式定义一个函数，预防如下：\n",
    "lambda 参数1，参数2：函数体或者表达式\n",
    "'''\n",
    "# 定义匿名函数：对两个数相加\n",
    "sum = lambda a,b: a + b\n",
    " \n",
    "# 调用sum函数\n",
    "print (\"相加后的值为 : \", sum(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "客舱号的首字母是客舱的类别\n",
    "'''\n",
    "#查看客舱号的内容\n",
    "full['Cabin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放客舱号信息\n",
    "cabinDf = pd.DataFrame()\n",
    "\n",
    "'''\n",
    "客场号的类别值是首字母，例如：\n",
    "C85 类别映射为首字母C\n",
    "'''\n",
    "full[ 'Cabin' ] = full[ 'Cabin' ].map(lambda c : c[0] )\n",
    "\n",
    "##使用get_dummies进行one-hot编码，列名前缀是Cabin\n",
    "cabinDf = pd.get_dummies( full['Cabin'] , prefix = 'Cabin' )\n",
    "\n",
    "cabinDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加one-hot编码产生的虚拟变量（dummy variables）到泰坦尼克号数据集full\n",
    "full = pd.concat([full,cabinDf],axis=1)\n",
    "\n",
    "#删掉客舱号这一列\n",
    "full.drop('Cabin',axis=1,inplace=True)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立家庭人数和家庭类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放家庭信息\n",
    "familyDf = pd.DataFrame()\n",
    "\n",
    "'''\n",
    "家庭人数=同代直系亲属数（Parch）+不同代直系亲属数（SibSp）+乘客自己\n",
    "（因为乘客自己也是家庭成员的一个，所以这里加1）\n",
    "'''\n",
    "familyDf[ 'FamilySize' ] = full[ 'Parch' ] + full[ 'SibSp' ] + 1\n",
    "\n",
    "'''\n",
    "家庭类别：\n",
    "小家庭Family_Single：家庭人数=1\n",
    "中等家庭Family_Small: 2<=家庭人数<=4\n",
    "大家庭Family_Large: 家庭人数>=5\n",
    "'''\n",
    "#if 条件为真的时候返回if前面内容，否则返回0\n",
    "familyDf[ 'Family_Single' ] = familyDf[ 'FamilySize' ].map( lambda s : 1 if s == 1 else 0 )\n",
    "familyDf[ 'Family_Small' ]  = familyDf[ 'FamilySize' ].map( lambda s : 1 if 2 <= s <= 4 else 0 )\n",
    "familyDf[ 'Family_Large' ]  = familyDf[ 'FamilySize' ].map( lambda s : 1 if 5 <= s else 0 )\n",
    "\n",
    "familyDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#添加one-hot编码产生的虚拟变量（dummy variables）到泰坦尼克号数据集full\n",
    "full = pd.concat([full,familyDf],axis=1)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#到现在我们已经有了这么多个特征了\n",
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以学习后面的课程后，再了解特征选择的方法。但是如果你已经具备了多种机器学习算法的知识，想提前学习，可以参考这些资料：\n",
    " \n",
    "* [如何做特征工程?](http://www.csuldw.com/2015/10/24/2015-10-24%20feature%20engineering/)\n",
    "* [如何使用sklearn进行特征工程？](http://www.cnblogs.com/jasonfreak/p/5448385.html)\n",
    "\n",
    "* [泰坦尼克号如何进行特征选择?](https://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关系数法：计算各个特征的相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#相关性矩阵\n",
    "corrDf = full.corr() \n",
    "corrDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "查看各个特征与生成情况（Survived）的相关系数，\n",
    "ascending=False表示按降序排列\n",
    "'''\n",
    "corrDf['Survived'].sort_values(ascending =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据各个特征与生成情况（Survived）的相关系数大小，我们选择了这几个特征作为模型的输入：\n",
    "\n",
    "头衔（前面所在的数据集titleDf）、客舱等级（pclassDf）、家庭大小（familyDf）、船票价格（Fare）、船舱号（cabinDf）、登船港口（embarkedDf）、性别（Sex）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征选择\n",
    "full_X = pd.concat( [titleDf,#头衔\n",
    "                     pclassDf,#客舱等级\n",
    "                     familyDf,#家庭大小\n",
    "                     full['Fare'],#船票价格\n",
    "                     cabinDf,#船舱号\n",
    "                     embarkedDf,#登船港口\n",
    "                     full['Sex']#性别\n",
    "                    ] , axis=1 )\n",
    "full_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用训练数据和某个机器学习算法得到机器学习模型，用测试数据评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 建立训练数据集和测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1）坦尼克号测试数据集因为是我们最后要提交给Kaggle的，里面没有生存情况的值，所以不能用于评估模型。\n",
    "我们将Kaggle泰坦尼克号项目给我们的测试数据，叫做预测数据集（记为pred,也就是预测英文单词predict的缩写）。\n",
    "也就是我们使用机器学习模型来对其生存情况就那些预测。\n",
    "2）我们使用Kaggle泰坦尼克号项目给的训练数据集，做为我们的原始数据集（记为source），\n",
    "从这个原始数据集中拆分出训练数据集（记为train：用于模型训练）和测试数据集（记为test：用于模型评估）。\n",
    "\n",
    "'''\n",
    "#原始数据集有891行\n",
    "sourceRow=891\n",
    "\n",
    "'''\n",
    "sourceRow是我们在最开始合并数据前知道的，原始数据集有总共有891条数据\n",
    "从特征集合full_X中提取原始数据集提取前891行数据时，我们要减去1，因为行号是从0开始的。\n",
    "'''\n",
    "#原始数据集：特征\n",
    "source_X = full_X.loc[0:sourceRow-1,:]\n",
    "#原始数据集：标签\n",
    "source_y = full.loc[0:sourceRow-1,'Survived']   \n",
    "\n",
    "#预测数据集：特征\n",
    "pred_X = full_X.loc[sourceRow:,:]\n",
    "'''\n",
    "上面代码解释：\n",
    "891行前面的数据是测试数据集，891行之后的数据是预测数据集。[sourceRow:,:]就是从891行开始到最后一行作为预测数据集\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "确保这里原始数据集取的是前891行的数据，不然后面模型会有错误\n",
    "'''\n",
    "#原始数据集有多少行\n",
    "print('原始数据集有多少行:',source_X.shape[0])\n",
    "#预测数据集大小\n",
    "print('原始数据集有多少行:',pred_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "从原始数据集（source）中拆分出训练数据集（用于模型训练train），测试数据集（用于模型评估test）\n",
    "train_test_split是交叉验证中常用的函数，功能是从样本中随机的按比例选取train data和test data\n",
    "train_data：所要划分的样本特征集\n",
    "train_target：所要划分的样本结果\n",
    "test_size：样本占比，如果是整数的话就是样本的数量\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#建立模型用的训练数据集和测试数据集\n",
    "train_X, test_X, train_y, test_y = train_test_split(source_X ,\n",
    "                                                    source_y,\n",
    "                                                    train_size=.8)\n",
    "\n",
    "#输出数据集大小\n",
    "print ('原始数据集特征：',source_X.shape, \n",
    "       '训练数据集特征：',train_X.shape ,\n",
    "      '测试数据集特征：',test_X.shape)\n",
    "\n",
    "print ('原始数据集标签：',source_y.shape, \n",
    "       '训练数据集标签：',train_y.shape ,\n",
    "      '测试数据集标签：',test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原始数据查看\n",
    "source_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 选择机器学习算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择一个机器学习算法，用于模型的训练。如果你是新手，建议从逻辑回归算法开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第1步：导入算法\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#第2步：创建模型：逻辑回归（logisic regression）\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机森林Random Forests Model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#支持向量机Support Vector Machines\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "#model3 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#model4 = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-nearest neighbors\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#model5 = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#model6 = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第3步：训练模型\n",
    "model.fit( train_X , train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类问题，score得到的是模型的正确率\n",
    "model.score(test_X , test_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.方案实施（Deployment）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 得到预测结果上传到Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用预测数据集到底预测结果，并保存到csv文件中，上传到Kaggle中，就可以看到排名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用机器学习模型，对预测数据集中的生存情况进行预测\n",
    "pred_Y = model.predict(pred_X)\n",
    "\n",
    "'''\n",
    "生成的预测值是浮点数（0.0,1,0）\n",
    "但是Kaggle要求提交的结果是整型（0,1）\n",
    "所以要对数据类型进行转换\n",
    "'''\n",
    "pred_Y=pred_Y.astype(int)\n",
    "#乘客id\n",
    "passenger_id = full.loc[sourceRow:,'PassengerId']\n",
    "#数据框：乘客id，预测生存情况的值\n",
    "predDf = pd.DataFrame( \n",
    "    { 'PassengerId': passenger_id , \n",
    "     'Survived': pred_Y } )\n",
    "predDf.shape\n",
    "predDf.head()\n",
    "#保存结果\n",
    "predDf.to_csv( 'titanic_pred.csv' , index = False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
