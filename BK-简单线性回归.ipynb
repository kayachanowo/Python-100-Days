{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果还没有安装机器学习包sklearn，需要先使用navigator可视化界面安装包：sklearn。\n",
    "\n",
    "不知道怎么操作安装包的，可以参考第1关的内容：https://www.zhihu.com/question/58033789/answer/254673663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集\n",
    "examDict={\n",
    "    '学习时间':[0.50,0.75,1.00,1.25,1.50,1.75,1.75,2.00,2.25,\n",
    "            2.50,2.75,3.00,3.25,3.50,4.00,4.25,4.50,4.75,5.00,5.50],\n",
    "    '分数':    [10,  22,  13,  43,  20,  22,  33,  50,  62,  \n",
    "              48,  55,  75,  62,  73,  81,  76,  64,  82,  90,  93]\n",
    "}\n",
    "examOrderDict=OrderedDict(examDict)\n",
    "examDf=pd.DataFrame(examOrderDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看数据集前5行\n",
    "examDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关系数：两个变量每单位的相关性程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取特征和标签\n",
    "#特征features\n",
    "exam_X=examDf.loc[:,'学习时间']\n",
    "#标签labes\n",
    "exam_y=examDf.loc[:,'分数']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制散点图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#散点图\n",
    "plt.scatter(exam_X, exam_y, color=\"b\", label=\"exam data\")\n",
    "\n",
    "#添加图标标签\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Score\")\n",
    "#显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#相关系数：corr返回结果是一个数据框，存放的是相关系数矩阵\n",
    "rDf=examDf.corr()\n",
    "print('相关系数矩阵：')\n",
    "rDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过以下游戏，熟悉和理解相关系数：\n",
    "1）此页面允许你使用滑块来更改相关系数，直观了解点的二维分布和相关系数大小，看看数据会如何呈现。\n",
    "相关性（长按此处可以复制）：http://rpsychologist.com/d3/correlation/\n",
    "\n",
    "2）猜测相关性的游戏，给出散点图，然后猜测两个变量的相关性系数。别一看这些乱乱的点就没有玩的兴趣了，其实玩起来还是很上瘾的。\n",
    "关键还得多玩几次找找感觉（长按此处可以复制）：\n",
    "http://istics.net/Correlations/\n",
    "\n",
    "3）参考资料《描述统计学》：https://www.zhihu.com/lives/916699160831483904"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.提取特征和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征features\n",
    "exam_X=examDf.loc[:,'学习时间']\n",
    "#标签labes\n",
    "exam_y=examDf.loc[:,'分数']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.建立训练数据和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_test_split是交叉验证中常用的函数，功能是从样本中随机的按比例选取训练数据（train）和测试数据（test）\n",
    "第一个参数：所要划分的样本特征\n",
    "第2个参数：所要划分的样本标签\n",
    "train_size：训练数据占比，如果是整数的话就是样本的数量\n",
    "'''\n",
    "\n",
    "'''\n",
    "sklearn包0.8版本以后，需要将之前的sklearn.cross_validation 换成sklearn.model_selection\n",
    "所以课程中的代码\n",
    "from sklearn.cross_validation import train_test_split \n",
    "更新为下面的代码\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#建立训练数据和测试数据\n",
    "X_train , X_test , y_train , y_test = train_test_split(exam_X ,\n",
    "                                                       exam_y ,\n",
    "                                                       train_size = .8)\n",
    "#输出数据大小\n",
    "print('原始数据特征：',exam_X.shape ,\n",
    "      '，训练数据特征：', X_train.shape , \n",
    "      '，测试数据特征：',X_test.shape )\n",
    "\n",
    "print('原始数据标签：',exam_y.shape ,\n",
    "      '训练数据标签：', y_train.shape ,\n",
    "      '测试数据标签：' ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制散点图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#散点图\n",
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train data\")\n",
    "plt.scatter(X_test, y_test, color=\"red\", label=\"test data\")\n",
    "\n",
    "#添加图标标签\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Score\")\n",
    "#显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.训练模型（使用训练数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "运行后会报错，因为这里输入的特征只有1个。注意看报错信息，通过这个例子也学会如何分析报错信息\n",
    "'''\n",
    "#第1步：导入线性回归\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# 第2步：创建模型：线性回归\n",
    "model = LinearRegression()\n",
    "#第3步：训练模型\n",
    "model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#将训练数据特征转换成二维数组XX行*1列\n",
    "X_train=X_train.values.reshape(-1,1)\n",
    "#将测试数据特征转换成二维数组行数*1列\n",
    "X_test=X_test.values.reshape(-1,1)\n",
    "\n",
    "#第1步：导入线性回归\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# 第2步：创建模型：线性回归\n",
    "model = LinearRegression()\n",
    "#第3步：训练模型\n",
    "model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "最佳拟合线：z=𝑎+𝑏x\n",
    "截距intercept：a\n",
    "回归系数：b\n",
    "'''\n",
    "\n",
    "#截距\n",
    "a=model.intercept_\n",
    "#回归系数\n",
    "b=model.coef_\n",
    "\n",
    "print('最佳拟合线：截距a=',a,'，回归系数b=',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "绘图的代码不需要看懂，后面会有专门的课程讲如何将机器学习结果可视化\n",
    "'''\n",
    "#绘图\n",
    "import matplotlib.pyplot as plt\n",
    "#训练数据散点图\n",
    "plt.scatter(X_train, y_train, color='blue', label=\"train data\")\n",
    "\n",
    "#训练数据的预测值\n",
    "y_train_pred = model.predict(X_train)\n",
    "#绘制最佳拟合线\n",
    "plt.plot(X_train, y_train_pred, color='black', linewidth=3, label=\"best line\")\n",
    "\n",
    "#添加图标标签\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Score\")\n",
    "#显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.模型评估（使用测试数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#线性回归的scroe方法得到的是决定系数R平方\n",
    "#评估模型:决定系数R平方\n",
    "model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "score内部会对第一个参数X_test用拟合曲线自动计算出y预测值，内容是决定系数R平方的计算过程。所以我们只用根据他的要求输入参数即可。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "绘图的代码不需要看懂，后面会有专门的课程讲如何将数据分析结果可视化\n",
    "\n",
    "下面绘图的目的是为了：把训练数据集（图中蓝色的点），和测试数据集（图中红色的点）放到一张图上来比较看\n",
    "'''\n",
    "\n",
    "#导入绘图包\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "第1步：绘制训练数据散点图\n",
    "'''\n",
    "plt.scatter(X_train, y_train, color='blue', label=\"train data\")\n",
    "\n",
    "'''\n",
    "第2步：用训练数据绘制最佳线\n",
    "'''\n",
    "#最佳拟合线训练数据的预测值\n",
    "y_train_pred = model.predict(X_train)\n",
    "#绘制最佳拟合线：标签用的是训练数据的预测值y_train_pred\n",
    "plt.plot(X_train, y_train_pred, color='black', linewidth=3, label=\"best line\")\n",
    "\n",
    "'''\n",
    "第3步：绘制测试数据的散点图\n",
    "'''\n",
    "plt.scatter(X_test, y_test, color='red', label=\"test data\")\n",
    "\n",
    "#添加图标标签\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Score\")\n",
    "#显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('coefficient of determination:', results.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('adjusted coefficient of determination:', results.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('regression coefficients:', results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print('predicted response:', results.fittedvalues, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicted response:', results.predict(x), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = sm.add_constant(np.arange(10).reshape((-1, 2)))\n",
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = results.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共享单车系统是一种服务，在这种服务中，自行车可以在短期内以价格或免费的方式提供给个人共享使用。美国一家自行车共享提供商BoomBikes最近由于持续的Covid-19流行，其收入大幅下降。该公司发现在当前的市场环境下很难维持下去。因此，它决定拿出一个深思熟虑的商业计划，以便一旦持续的封锁结束，经济恢复到健康状态，就能够加快收入。\n",
    "\n",
    "在这样的尝试中，BoomBikes渴望了解人们对共享自行车的需求。他们计划这样做的目的是，一旦形势好转，从其他服务提供商中脱颖而出，赚取巨额利润，就可以满足人民的需要。\n",
    "\n",
    "他们与一家咨询公司签约，以了解这些共享自行车的需求所依赖的因素。具体来说，他们想了解影响美国市场对这些共享自行车需求的因素。公司想知道：\n",
    "\n",
    "哪些变量对预测共享单车的需求有重要意义。\n",
    "根据各种气象调查和人们的生活方式，这些变量对自行车需求的描述程度如何，这家服务供应商公司收集了大量基于某些因素的美国市场自行车日需求数据集。\n",
    "\n",
    "商业目标：你需要用可用的独立变量对共享单车的需求进行建模。管理层将使用它来了解不同功能的需求是如何变化的。他们可以相应地操纵业务策略以满足需求水平和满足客户的期望。此外，该模型将是管理层了解新市场需求动态的一个好方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "\n",
    "bike= pd.read_csv(\"day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if there are any missing values in the dataset\n",
    "\n",
    "import missingno as mn\n",
    "mn.matrix(bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike['dteday'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike['dteday'] =  pd.to_datetime(bike['dteday'],format='%Y-%m-%d')\n",
    "bike['dteday'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike['year'] = pd.DatetimeIndex(bike['dteday']).year\n",
    "bike['month'] = pd.DatetimeIndex(bike['dteday']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.drop(['yr','mnth'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the redundant variable holiday as the workingday column covers enough information that is required.\n",
    "\n",
    "bike.drop('holiday',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the dteday,instant,casual and registered columns.\n",
    "\n",
    "bike.drop(['dteday','instant','casual','registered'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming some columns for better understanding\n",
    "\n",
    "bike.rename(columns={'hum':'humidity','cnt':'count'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(15,8))\n",
    "#Violin plot for yearly distribution of counts\n",
    "sns.violinplot(x='year',y='count',data=bike[['year','count']])\n",
    "ax.set_title('Yearly distribution of counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Barplot for workingdaydistribution of counts\n",
    "sns.barplot(data=bike,x='workingday',y='count',hue='season')\n",
    "ax.set_title('Holiday wise distribution of counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {1:'spring',2:'summer',3:'fall',4:'winter'}\n",
    "bike['season'] = bike['season'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('season','count',data=bike);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {1:'Clear',2:'Mist',3:'Light Snow',4:'Heavy Rain'}\n",
    "bike['weathersit'] = bike['weathersit'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('weathersit','count',data=bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {1:'working_day',0:'Holiday'}\n",
    "bike['workingday'] = bike['workingday'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('workingday','count',data=bike,palette='cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {2012:1,2011:0}\n",
    "bike['year'] = bike['year'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('year','count',data=bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'June',7:'July',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'}\n",
    "bike['month'] = bike['month'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot('month','count',hue='year',data=bike,palette='Paired');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\n",
    "bike['weekday'] = bike['weekday'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.groupby('weekday')['count'].max().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('temp','count',data=bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('atemp','count',data=bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('humidity','count',data=bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('windspeed','count',data=bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(bike['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(bike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "sns.heatmap(bike.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= bike[['temp','atemp','humidity','windspeed']]\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.drop('atemp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = pd.get_dummies(bike['season'],drop_first=True)\n",
    "\n",
    "working_day = pd.get_dummies(bike['workingday'],drop_first=True)\n",
    "\n",
    "weather= pd.get_dummies(bike['weathersit'],drop_first=True)\n",
    "\n",
    "month= pd.get_dummies(bike['month'],drop_first=True)\n",
    "\n",
    "week_day= pd.get_dummies(bike['weekday'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike= pd.concat([bike,seasons,working_day,weather,month,week_day],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the categorical variables as they are already dummy-encoded.\n",
    "\n",
    "bike.drop(['season','workingday','weathersit','weekday','month'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(bike, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 10))\n",
    "sns.heatmap(df_train.corr(), annot = True,cmap=\"BuPu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaler() to all the columns except the'dummy' variables.\n",
    "\n",
    "num_vars=['temp','humidity','windspeed','count']\n",
    "df_train[num_vars]= scaler.fit_transform(df_train[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('temp','count',data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('count')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RFE and LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RFE with the output number of the variable equal to 10\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lm,10) # running RFE\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_test dataframe with RFE selected variables\n",
    "X_train_rfe = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant variable \n",
    "import statsmodels.api as sm  \n",
    "X_train_rfe = sm.add_constant(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sm.OLS(y_train,X_train_rfe).fit()   # Running the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new= X_train_rfe.drop('const',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "X = X_train_new\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lm.predict(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_pred), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars=['temp','humidity','windspeed','count']\n",
    "\n",
    "df_test[num_vars]= scaler.transform(df_test[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.pop('count')\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use our model to make predictions.\n",
    "\n",
    "# Creating X_test_new dataframe by dropping variables from X_test\n",
    "X_test_new = X_test[X_train_new.columns]\n",
    "\n",
    "# Adding a constant variable \n",
    "X_test_new = sm.add_constant(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_test_pred = lm.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread.\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test,y_test_pred)\n",
    "fig.suptitle('Actual vs Predictions', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Actual', fontsize=18)                          # X-label\n",
    "plt.ylabel('Predictions', fontsize=16)                          # Y-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "线性回归的假设：误差项为正态分布。\n",
    "训练和测试精度几乎相等，因此不存在过度/不足的情况。\n",
    "预测值与实际值呈线性关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "The top 5 variables that are seen effecting and benefitting the Bike Rental count are as follows:\n",
    "\n",
    "Spring season : -0.5505\n",
    "Temperature : 0.4311\n",
    "Mist : -0.3427\n",
    "Winter : 0.3603\n",
    "July : -0.3114"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
